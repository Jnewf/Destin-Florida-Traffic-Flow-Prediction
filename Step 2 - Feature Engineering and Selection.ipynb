{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82c1c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Creating time-based features...\n",
      "Creating weather-related features...\n",
      "Creating traffic-related features...\n",
      "Analyzing feature importance...\n",
      "\n",
      "Data saved to engineered_traffic_data.csv\n",
      "\n",
      "Feature Correlations with Traffic Count:\n",
      "traffic_count       1.000000\n",
      "traffic_density     0.959020\n",
      "rolling_avg_3h      0.949396\n",
      "hour                0.399000\n",
      "daily_total         0.233870\n",
      "temperature         0.070084\n",
      "humidity            0.047557\n",
      "wind_speed          0.046900\n",
      "weather_severity    0.040620\n",
      "precipitation       0.004272\n",
      "day_of_week_num    -0.016191\n",
      "visibility         -0.019112\n",
      "month              -0.031066\n",
      "is_weekend         -0.052858\n",
      "hour_sin           -0.341407\n",
      "hour_cos           -0.822100\n",
      "Name: traffic_count, dtype: float64\n",
      "\n",
      "Summary of Key Features:\n",
      "       traffic_count  rolling_avg_3h  traffic_density   temperature  \\\n",
      "count   16107.000000    16107.000000     16107.000000  16107.000000   \n",
      "mean      900.273670      900.277416         0.041764     70.566155   \n",
      "std       566.625179      546.606876         0.025816     12.375593   \n",
      "min        23.000000       33.333333         0.001169     31.930000   \n",
      "25%       295.000000      328.666667         0.014198     62.830000   \n",
      "50%      1033.000000     1014.333333         0.049053     72.160000   \n",
      "75%      1420.000000     1411.833333         0.063703     79.660000   \n",
      "max      1918.000000     1842.333333         0.102131    100.220000   \n",
      "\n",
      "         visibility    wind_speed  \n",
      "count  16107.000000  16107.000000  \n",
      "mean    9690.925002      8.674384  \n",
      "std     1432.086361      4.475895  \n",
      "min      201.000000      0.000000  \n",
      "25%    10000.000000      5.750000  \n",
      "50%    10000.000000      8.050000  \n",
      "75%    10000.000000     11.500000  \n",
      "max    10000.000000     31.070000  \n",
      "\n",
      "Unique values in categorical features:\n",
      "\n",
      "weather_main:\n",
      "Clear           8862\n",
      "Clouds          3151\n",
      "Rain            2329\n",
      "Mist             913\n",
      "Haze             236\n",
      "Fog              210\n",
      "Drizzle          190\n",
      "Thunderstorm     175\n",
      "Smoke             39\n",
      "Squall             2\n",
      "Name: weather_main, dtype: int64\n",
      "\n",
      "visibility_category:\n",
      "Moderate    15566\n",
      "Low           377\n",
      "Very Low      164\n",
      "Good            0\n",
      "Name: visibility_category, dtype: int64\n",
      "\n",
      "temp_category:\n",
      "Warm        7384\n",
      "Moderate    5697\n",
      "Hot         1883\n",
      "Cold        1141\n",
      "Freezing       2\n",
      "Name: temp_category, dtype: int64\n",
      "\n",
      "congestion_level:\n",
      "Low         4034\n",
      "High        4034\n",
      "Moderate    4021\n",
      "Severe      4018\n",
      "Name: congestion_level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load and prepare the merged dataset.\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"Create time-based features.\"\"\"\n",
    "    print(\"Creating time-based features...\")\n",
    "    \n",
    "    # Extract time components\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24)\n",
    "    \n",
    "    # Create peak hour flags\n",
    "    df['is_morning_peak'] = df['hour'].between(6, 9)\n",
    "    df['is_evening_peak'] = df['hour'].between(16, 19)\n",
    "    \n",
    "    # Add day of week encoding\n",
    "    df['day_of_week_num'] = pd.to_datetime(df['date']).dt.dayofweek\n",
    "    \n",
    "    # Create weekend dummy (already exists but ensuring numeric)\n",
    "    df['is_weekend'] = df['is_weekend'].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_weather_features(df):\n",
    "    \"\"\"Create weather-related features.\"\"\"\n",
    "    print(\"Creating weather-related features...\")\n",
    "    \n",
    "    # Create weather condition categories\n",
    "    weather_severity = {\n",
    "        'Clear': 0,\n",
    "        'Clouds': 1,\n",
    "        'Mist': 2,\n",
    "        'Fog': 3,\n",
    "        'Rain': 4,\n",
    "        'Snow': 5,\n",
    "        'Thunderstorm': 6\n",
    "    }\n",
    "    df['weather_severity'] = df['weather_main'].map(weather_severity)\n",
    "    \n",
    "    # Create visibility categories\n",
    "    df['visibility_category'] = pd.cut(df['visibility'], \n",
    "                                     bins=[0, 1000, 5000, 10000, float('inf')],\n",
    "                                     labels=['Very Low', 'Low', 'Moderate', 'Good'])\n",
    "    \n",
    "    # Create temperature categories\n",
    "    df['temp_category'] = pd.cut(df['temperature'],\n",
    "                                bins=[-float('inf'), 32, 50, 70, 85, float('inf')],\n",
    "                                labels=['Freezing', 'Cold', 'Moderate', 'Warm', 'Hot'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_traffic_features(df):\n",
    "    \"\"\"Create traffic-related features.\"\"\"\n",
    "    print(\"Creating traffic-related features...\")\n",
    "    \n",
    "    # Calculate rolling averages\n",
    "    df['rolling_avg_3h'] = df.groupby('direction')['traffic_count'].transform(\n",
    "        lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "    \n",
    "    # Calculate traffic density (traffic_count relative to daily_total)\n",
    "    df['traffic_density'] = df['traffic_count'] / df['daily_total']\n",
    "    \n",
    "    # Create congestion levels\n",
    "    df['congestion_level'] = pd.qcut(df['traffic_count'], \n",
    "                                    q=4, \n",
    "                                    labels=['Low', 'Moderate', 'High', 'Severe'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    \"\"\"Perform feature selection and analysis.\"\"\"\n",
    "    print(\"Analyzing feature importance...\")\n",
    "    \n",
    "    # Prepare numeric features for correlation analysis\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "    numeric_df = df[numeric_features].copy()\n",
    "    \n",
    "    # Calculate correlation with traffic_count\n",
    "    correlations = numeric_df.corr()['traffic_count'].sort_values(ascending=False)\n",
    "    \n",
    "    # Create correlation heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(numeric_df[numeric_features].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    df = load_and_prepare_data('merged_traffic_weather_data.csv')\n",
    "    \n",
    "    # Feature engineering\n",
    "    df = create_time_features(df)\n",
    "    df = create_weather_features(df)\n",
    "    df = create_traffic_features(df)\n",
    "    \n",
    "    # Feature selection\n",
    "    correlations = select_features(df)\n",
    "    \n",
    "    # Save engineered features\n",
    "    output_file = 'engineered_traffic_data.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nData saved to {output_file}\")\n",
    "    \n",
    "    # Print feature correlations with traffic count\n",
    "    print(\"\\nFeature Correlations with Traffic Count:\")\n",
    "    print(correlations)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary of Key Features:\")\n",
    "    print(df[['traffic_count', 'rolling_avg_3h', 'traffic_density', \n",
    "              'temperature', 'visibility', 'wind_speed']].describe())\n",
    "    \n",
    "    # Print unique values in categorical features\n",
    "    print(\"\\nUnique values in categorical features:\")\n",
    "    categorical_features = ['weather_main', 'visibility_category', \n",
    "                          'temp_category', 'congestion_level']\n",
    "    for feature in categorical_features:\n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(df[feature].value_counts())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7604e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
