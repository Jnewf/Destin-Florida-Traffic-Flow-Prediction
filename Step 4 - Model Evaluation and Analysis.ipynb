{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99312b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model results...\n",
      "\n",
      "Decision Tree Classifier Evaluation:\n",
      "\n",
      "Class-wise Accuracy:\n",
      "Class_0: 0.8969\n",
      "Class_1: 0.9794\n",
      "Class_2: 0.9138\n",
      "Class_3: 0.9192\n",
      "\n",
      "Total Misclassifications: 236\n",
      "\n",
      "Misclassification Distribution:\n",
      "Actual_Congestion  Predicted_Congestion\n",
      "0                  2                       12\n",
      "                   3                       71\n",
      "1                  2                       16\n",
      "2                  0                       55\n",
      "                   1                       17\n",
      "                   3                        1\n",
      "3                  0                       64\n",
      "dtype: int64\n",
      "\n",
      "Linear Regression Model Evaluation:\n",
      "Mean Absolute Error: 65.01\n",
      "Mean Absolute Percentage Error: 14.03%\n",
      "\n",
      "Error Percentiles:\n",
      "25th percentile: 22.97\n",
      "Median error: 49.25\n",
      "75th percentile: 90.32\n",
      "90th percentile: 140.49\n",
      "95th percentile: 183.88\n",
      "99th percentile: 268.40\n",
      "\n",
      "Evaluation complete. Check the generated visualization files for detailed analysis.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import joblib\n",
    "\n",
    "def load_results():\n",
    "    \"\"\"Load the saved model results.\"\"\"\n",
    "    print(\"Loading model results...\")\n",
    "    dt_results = pd.read_csv('decision_tree_results.csv')\n",
    "    lr_results = pd.read_csv('linear_regression_results.csv')\n",
    "    return dt_results, lr_results\n",
    "\n",
    "def evaluate_classification_model(results):\n",
    "    \"\"\"Evaluate the decision tree classifier performance.\"\"\"\n",
    "    print(\"\\nDecision Tree Classifier Evaluation:\")\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(results['Actual_Congestion'], results['Predicted_Congestion'])\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix - Traffic Congestion Classification')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate class-wise accuracy\n",
    "    class_accuracy = {}\n",
    "    for i in range(4):  # 4 congestion levels\n",
    "        class_accuracy[f'Class_{i}'] = cm[i, i] / np.sum(cm[i, :])\n",
    "    \n",
    "    print(\"\\nClass-wise Accuracy:\")\n",
    "    for class_name, acc in class_accuracy.items():\n",
    "        print(f\"{class_name}: {acc:.4f}\")\n",
    "    \n",
    "    # Calculate misclassification analysis\n",
    "    misclassified = results[results['Actual_Congestion'] != results['Predicted_Congestion']]\n",
    "    print(f\"\\nTotal Misclassifications: {len(misclassified)}\")\n",
    "    print(\"\\nMisclassification Distribution:\")\n",
    "    print(misclassified.groupby(['Actual_Congestion', 'Predicted_Congestion']).size())\n",
    "\n",
    "def evaluate_regression_model(results):\n",
    "    \"\"\"Evaluate the linear regression model performance.\"\"\"\n",
    "    print(\"\\nLinear Regression Model Evaluation:\")\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    mae = np.mean(np.abs(results['Actual_Traffic'] - results['Predicted_Traffic']))\n",
    "    mape = np.mean(np.abs((results['Actual_Traffic'] - results['Predicted_Traffic']) / results['Actual_Traffic'])) * 100\n",
    "    \n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
    "    \n",
    "    # Plot actual vs predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(results['Actual_Traffic'], results['Predicted_Traffic'], alpha=0.5)\n",
    "    plt.plot([results['Actual_Traffic'].min(), results['Actual_Traffic'].max()], \n",
    "             [results['Actual_Traffic'].min(), results['Actual_Traffic'].max()], \n",
    "             'r--', lw=2)\n",
    "    plt.xlabel('Actual Traffic Count')\n",
    "    plt.ylabel('Predicted Traffic Count')\n",
    "    plt.title('Actual vs Predicted Traffic Volume')\n",
    "    plt.savefig('regression_scatter.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Error distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    errors = results['Predicted_Traffic'] - results['Actual_Traffic']\n",
    "    sns.histplot(errors, bins=50)\n",
    "    plt.title('Prediction Error Distribution')\n",
    "    plt.xlabel('Prediction Error')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('error_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate error percentiles\n",
    "    error_percentiles = np.percentile(np.abs(errors), [25, 50, 75, 90, 95, 99])\n",
    "    print(\"\\nError Percentiles:\")\n",
    "    print(f\"25th percentile: {error_percentiles[0]:.2f}\")\n",
    "    print(f\"Median error: {error_percentiles[1]:.2f}\")\n",
    "    print(f\"75th percentile: {error_percentiles[2]:.2f}\")\n",
    "    print(f\"90th percentile: {error_percentiles[3]:.2f}\")\n",
    "    print(f\"95th percentile: {error_percentiles[4]:.2f}\")\n",
    "    print(f\"99th percentile: {error_percentiles[5]:.2f}\")\n",
    "\n",
    "def analyze_feature_importance():\n",
    "    \"\"\"Analyze and visualize feature importance from both models.\"\"\"\n",
    "    # Load the models\n",
    "    dt_model = joblib.load('decision_tree_model.joblib')\n",
    "    lr_model = joblib.load('linear_regression_model.joblib')\n",
    "    \n",
    "    # Get feature names (from the training script output)\n",
    "    feature_names = [\n",
    "        'hour_sin', 'hour_cos', 'is_morning_peak', 'is_evening_peak',\n",
    "        'is_weekend', 'day_of_week_num', 'month', 'temperature', \n",
    "        'humidity', 'wind_speed', 'visibility', 'precipitation',\n",
    "        'weather_severity', 'rolling_avg_3h', 'traffic_density'\n",
    "    ]\n",
    "    \n",
    "    # Create feature importance plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Decision Tree importance\n",
    "    importance_dt = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': dt_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(importance_dt['feature'], importance_dt['importance'])\n",
    "    plt.title('Decision Tree Feature Importance')\n",
    "    \n",
    "    # Linear Regression coefficients\n",
    "    importance_lr = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': np.abs(lr_model.coef_)\n",
    "    }).sort_values('coefficient', ascending=True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(importance_lr['feature'], importance_lr['coefficient'])\n",
    "    plt.title('Linear Regression Feature Importance')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    # Load results\n",
    "    dt_results, lr_results = load_results()\n",
    "    \n",
    "    # Evaluate models\n",
    "    evaluate_classification_model(dt_results)\n",
    "    evaluate_regression_model(lr_results)\n",
    "    \n",
    "    # Analyze feature importance\n",
    "    analyze_feature_importance()\n",
    "    \n",
    "    print(\"\\nEvaluation complete. Check the generated visualization files for detailed analysis.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99989a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
